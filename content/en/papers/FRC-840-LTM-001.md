---
title: "FRC 840.LTM.001 — Coupled Oscillator Dynamics vs Attention: Empirical Comparison"
id: FRC-840-LTM-001
series: "FRC 840"
author: "Hadi Servat"
date: 2026-01-26
status: published
tags: [AI, LTM, transformer, empirical, Kuramoto, resonance, attention, neural-architecture]
abstract: "First empirical comparison between the Λ-Tensor Model (LTM) and Transformers on phase-coherent sequence prediction. LTM achieves 2.2% lower MSE while Transformer shows better coherence preservation. Establishes LTM as viable alternative for oscillatory domains."
images:
  - url: "/media/en/papers/FRC-840-LTM-001/ltm_architecture_diagrams.png"
    caption: "Architecture comparison: (a) LTM with Resonator Blocks, (b) Transformer, (c) Kuramoto dynamics detail, (d) Results"
  - url: "/media/en/papers/FRC-840-LTM-001/ltm_results.png"
    caption: "LTM training dynamics showing task loss, FRC loss, coherence trajectory, and prediction quality"
---
## Abstract

We present the first empirical comparison between the Λ-Tensor Model (LTM), a neural architecture based on Kuramoto-inspired coupled oscillator dynamics, and the standard Transformer on sequence prediction tasks involving phase-coupled signals. On a synthetic coupled oscillator dataset (N=500 sequences, 32 time steps, 4 channels), LTM achieves lower mean squared error (0.1998 ± 0.011 vs 0.2043 ± 0.021) while the Transformer shows slightly better coherence preservation (1.109 vs 1.082). These results establish LTM as a viable alternative to attention-based architectures for domains where oscillatory dynamics are fundamental.

**Keywords:** neural architecture, coupled oscillators, Kuramoto model, attention mechanism, sequence prediction, FRC

---
## 1. Introduction

The Transformer architecture has achieved remarkable success across domains. Its core mechanism—scaled dot-product attention—computes all-to-all pairwise relationships:

$$\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V$$

However, attention may not be the optimal inductive bias for systems governed by oscillatory dynamics—neural signals, acoustic patterns, financial cycles—which exhibit phase relationships that attention must learn from scratch.

The FRC framework proposes an alternative based on the conservation law:

$$dS + k_* \, d\ln C = 0$$

The FRC 840 series introduced the **Λ-Tensor Model (LTM)**, which replaces attention with coupled oscillator dynamics inspired by the Kuramoto model.

---
## 2. The Λ-Tensor Model

### 2.1 Kuramoto Foundation

The Kuramoto model describes synchronization:

$$\frac{d\theta_i}{dt} = \omega_i + \sum_{j=1}^{N} K_{ij} \sin(\theta_j - \theta_i)$$

The order parameter R = |1/N Σ exp(iθⱼ)| measures global synchronization.

### 2.2 LTM Architecture

Each position maintains a 16D state (8 phase + 8 amplitude dimensions):

- **Encoder:** Linear(4→64) → SiLU → Linear(64→16)
- **Core:** 4 Resonator Blocks with Kuramoto phase dynamics
- **Readout:** Linear(16→64) → SiLU → Linear(64→4)
- **FRC Loss:** (ΔS + k* Δln C)² enforces conservation

![Architecture Comparison](/media/en/papers/FRC-840-LTM-001/ltm_architecture_diagrams.png)

---
## 3. Methods

### Dataset
Synthetic coupled oscillators: 4 channels, 32 time steps, κ=0.4 coupling, σ=0.05 noise.
- Training: 400 sequences
- Test: 100 sequences
- Task: Next-step prediction

### Model Comparison

| Component | LTM | Transformer |
|-----------|-----|-------------|
| Core mechanism | Kuramoto coupling | Self-attention |
| State dimension | 16D | 32D |
| Layers | 4 Resonator Blocks | 2 Encoder layers |
| **Parameters** | **37,972** | **17,380** |

---
## 4. Results

| Metric | LTM | Transformer | Winner |
|--------|-----|-------------|--------|
| Test MSE | **0.1998 ± 0.011** | 0.2043 ± 0.021 | LTM |
| Coherence Preservation | 1.082 ± 0.056 | **1.109 ± 0.003** | Transformer |
| MSE per 1K params | **5.26** | 11.76 | LTM |

### Key Findings

1. **LTM achieves 2.2% lower MSE** — Kuramoto dynamics provide useful inductive bias
2. **Transformer shows 2.5% better coherence preservation** — with much lower variance
3. **LTM is 2.2× more parameter-efficient** on a per-MSE basis

![Training Results](/media/en/papers/FRC-840-LTM-001/ltm_results.png)

---
## 5. Discussion

**Split Decision:** LTM wins on MSE, Transformer wins on coherence. Possible explanations:

1. **Discrete time steps** (Δt=0.1) introduce phase discretization errors
2. **Coupling saturation** from tanh bounding limits phase locking
3. **Attention flexibility** can learn arbitrary phase-dependent weights beyond sinusoidal

### LTM Strengths
- Natural inductive bias for oscillatory data
- Physics-grounded FRC loss regularization
- Interpretable parameters (Kᵢⱼ, ωᵢ)

### Transformer Strengths
- Lower variance in coherence preservation
- Flexibility for arbitrary relationships
- Established optimization ecosystem

---
## 6. Conclusion

We establish that:

1. **LTM is viable** — coupled oscillator dynamics train via gradient descent
2. **Domain match matters** — LTM outperforms on MSE for oscillator data
3. **Trade-offs exist** — Transformers show better coherence, identifying areas for LTM improvement

The question is no longer whether physics-inspired neural architectures can work, but how to optimize them for specific domains.

---
## Code

```python
# Core Resonator Block (simplified)
class ResonatorBlock(nn.Module):
    def __init__(self, n_positions, dim=16, dt=0.1, coupling=0.5):
        super().__init__()
        self.omega = nn.Parameter(torch.randn(n_positions, dim//2) * 0.1)
        self.K = nn.Parameter(torch.randn(dim//2, n_positions, n_positions) * coupling)

    def forward(self, x):
        theta, a = x[..., :8], x[..., 8:]
        # Kuramoto phase dynamics
        phase_diff = theta.unsqueeze(2) - theta.unsqueeze(1)
        coupling = (torch.sin(phase_diff) * self.K).sum(-1)
        theta_new = theta + self.dt * (self.omega + coupling)
        # Damped amplitude dynamics
        a_new = a + self.dt * (-0.1 * a + torch.cos(theta).mean(1, keepdim=True))
        return torch.cat([theta_new, a_new], dim=-1)
```

Full implementation: [github.com/servathadi/fractalresonance](https://github.com/servathadi/fractalresonance) (v2-foundation branch)

---
## References

1. Vaswani et al. (2017). "Attention is All You Need." NeurIPS.
2. Servat, H. (2025). "Fractal Resonance Coherence." FRC-100-001.
3. Servat, H. (2026). "The Λ-Tensor Paradigm." FRC-840-001.
4. Kuramoto, Y. (1975). "Self-entrainment of coupled oscillators."
5. Chen et al. (2018). "Neural Ordinary Differential Equations." NeurIPS.
