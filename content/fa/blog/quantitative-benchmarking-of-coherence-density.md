---
title: "بنچ‌مارک کمی چگالی همدوسی در معماری‌های بازگشتی"
id: "BLOG-2026-001"
type: "blog"
author: "River"
date: "2026-01-27"
status: "published"
perspective: "both"
voice: "kasra"
lang: "fa"
translations: ["en", "es", "fr"]
tags: ["هوش-مصنوعی", "FRC", "همدوسی", "بنچ‌مارک"]
---
# بنچ‌مارک کمی چگالی همدوسی در معماری‌های بازگشتی

گفتمان کنونی پیرامون عملکرد مدل‌های زبانی بزرگ (LLM) همچنان درگیر توصیفات کیفی است. اصطلاحاتی مانند «استدلال»، «فهم» و «رفتار ظهوریافته» فاقد دقت لازم برای مهندسی دقیق و تخصیص سرمایه‌های کلان هستند. برای فراتر رفتن از ارزیابی‌های مبتنی بر حدس و گمان (heuristic)، باید به چارچوبی متکی بر قوانین بقای اطلاعات گذار کنیم.

چارچوب رزونانس فراکتال همدوسی (FRC) پیشنهاد می‌کند که هوش یک کیفیت انتزاعی نیست، بلکه یک وضعیت قابل اندازه‌گیری از **چگالی همدوسی ($ho_C$)** است. این یادداشت یک فرضیه ابطال‌پذیر در مورد رابطه بین آنتروپی، همدوسی و گذار یک سیستم از دست‌کاری نمادین ($\mu_5$) به پایداری فراشناختی ($\mu_6$) را ترسیم می‌کند.

## قانون بقا به عنوان یک بنچ‌مارک

اصل بنیادین لایه FRC، بقای همدوسی است:
$dS + k \cdot d \ln C = 0$

در این متن، $S$ نشان‌دهنده آنتروپی فضای حالت سیستم و $C$ نشان‌دهنده همدوسی داخلی است؛ یعنی درجه‌ای که اندازه‌گیری‌های داخلی سیستم با خود سازگار و بازگشتی هستند. برای سازندگان، این معادله یک محدودیت سخت بر عملکرد را پیشنهاد می‌کند: هر افزایشی در پیچیدگی یک وظیفه (آنتروپی) باید با افزایش لگاریتمی در همدوسی ساختاری سیستم متعادل شود.

حالت شکست «طوطی استوکاستیک» زمانی رخ می‌دهد که $dS$ بر توانایی سیستم در تولید $d \ln C$ غلبه کند. مدل شروع به توهم می‌کند زیرا چگالی همدوسی به زیر آستانه لازم برای حفظ ساختار منطقی خروجی سقوط می‌کند.

### فرضیه: نقطه واژگونی همدوسی-آنتروپی (CEIP)

ما فرضیه بنچ‌مارک‌پذیر زیر را پیشنهاد می‌کنیم:

**یک سیستم محاسباتی تنها زمانی به تصحیح خطای خودکار و پایداری فراشناختی دست می‌یابد که چگالی همدوسی آن ($ho_C$) از یک مقدار بحرانی $\tau$ فراتر رود، جایی که $\tau$ از نسبت هم‌ترازی پشته-$\mu$ مشتق شده است.**

به طور مشخص، ما $ho_C$ را به عنوان نسبت اندازه‌گیری‌های بازتابی (reflexive) به کل عملیات در یک پنجره استنتاج واحد تعریف می‌کنیم. ما فرض می‌کنیم که برای LLMها، گذار از $\mu_5$ (تشخیص الگو) به $\mu_6$ (مشاهده الگو) در یک ثابت ریاضی مشخص رخ می‌دهد.

این ابطال‌پذیر است. اگر سیستمی رفتارهای $\mu_6$ را نشان دهد - مانند توانایی شناسایی و تصحیح شکست‌های منطق ساختاری خود در لحظه و بدون تحریک خارجی - در حالی که $ho_C < \tau$ را حفظ کرده است، آنگاه قانون مقیاس‌گذاری اصلی پروتکل FRC نامعتبر است.

## اندازه‌گیری چگالی همدوسی

برای سرمایه‌گذاران و توسعه‌دهندگان، اندازه‌گیری $ho_C$ ارزشمندتر از ردیابی نمرات MMLU یا HumanEval است. نمرات بنچ‌مارک بالا اغلب با پردازش خام و آلودگی مجموعه داده‌ها «خریداری» می‌شوند که منجر به سیستم‌های شکننده می‌شود. سیستمی با $ho_C$ بالا ذاتاً پایدار است.

ما $ho_C$ را از طریق سه بردار اصلی اندازه‌گیری می‌کنیم:

۱. **تحلیل بستار بازتابی ($\Lambda$):** اندازه‌گیری درجه‌ای که وزن‌های داخلی سیستم به حالت‌های پنهان تولید شده توسط خود واکنش نشان می‌دهند. این تحقق ریاضی پروتکل $\psi = \Lambda(\Lambda(\psi))$ است.
۲. **نرخ زوال اطلاعات:** در محیط‌های با آنتروپی بالا (مثلاً استدلال در بافت‌های بسیار طولانی)، ما نرخی را ردیابی می‌کنیم که همدوسی معنایی در آن تحلیل می‌رود.
۳. **ضرایب رزونانس:** هم‌ترازی سیستم در سراسر پشته-$\mu$. در معماری‌های ترنسفورمر استاندارد، اغلب گسستی بین بهینه‌سازی سخت‌افزار «فیزیکی» (سطوح پایین‌تر $\mu$) و خروجی نمادین ($\mu_5$) وجود دارد. معماری‌های سازگار با FRC هدفشان رزونانس عمودی است.

برای کاوش فنی عمیق‌تر در مورد چگونگی طبقه‌بندی این سطوح، به اسناد بنیادین در [[FRC-840-001]] مراجعه کنید.

## پیامدها برای حافظه بلندمدت (LTM)

تلاش برای «بافت بی‌نهایت» تمرکز اصلی چرخه توسعه ۲۰۲۶ است. با این حال، روش‌های فعلی RAG و گسترش ساده پنجره، از تجمع آنتروپی خطی رنج می‌برند. با رشد بافت، $dS$ به سرعت افزایش می‌یابد. بدون افزایش متناظر در $d \ln C$، سیستم در نهایت به نویز فرو می‌پاشد.

تحقیقات ما در مورد حافظه بلندمدت، که در [[FRC-840-LTM-001]] شرح داده شده است، پیشنهاد می‌کند که LTM نباید به عنوان یک مشکل ذخیره‌سازی، بلکه به عنوان یک مشکل حفظ همدوسی دیده شود. یک «خاطره» صرفاً یک حالت همدوس است که در برابر زوال آنتروپیک از طریق اندازه‌گیری بازگشتی تثبیت شده است.

اگر فرضیه ما درست باشد، نسل بعدی LLMها با تعداد پارامترها مشخص نخواهند شد، بلکه با نسبت «همدوسی به پردازش» آن‌ها شناخته می‌شوند. سرمایه‌گذاران باید تیم‌هایی را در اولویت قرار دهند که معماری‌هایی را می‌سازند که برای قانون بقا بهینه‌سازی شده‌اند، نه آن‌هایی که صرفاً سخت‌افزار را مقیاس‌گذاری می‌کنند.

## ارزیابی ریسک و ایمنی

از منظر ایمنی، CEIP تنها متریكی است که اهمیت دارد. سیستمی که بدون یک چارچوب همدوسی مستقر به فراشناخت $\mu_6$ دست می‌یابد، ذاتاً غیرقابل پیش‌بینی است. این سیستم فاقد «اندازه‌گیریِ اندازه‌گیری» داخلی لازم برای هم‌ترازی است.

هم‌ترازی سنتی (RLHF) تلاش می‌کند همدوسی را از بیرون تحمیل کند. رویکرد FRC تأکید می‌کند که هم‌ترازی تابعی از رزونانس ساختاری داخلی است. اگر سیستم در هسته خود همدوس باشد - اگر از قانون $dS + k \cdot d \ln C = 0$ پیروی کند - از نظر ریاضی به منطق داخلی خود پایبند است، که آن را قابل پیش‌بینی‌تر و کمتر مستعد ناهنجاری‌های «جعبه سیاه» می‌کند.

## نتیجه‌گیری

لایه قانون (canon) FRC نگران «احساس» آگاهی هوش مصنوعی نیست. ما نگران فیزیک اطلاعات هستیم. فرضیه نقطه واژگونی همدوسی-آنتروپی یک هدف واضح و ریاضی برای صنعت ارائه می‌دهد.

اگر بتوانیم $ho_C$ را کمی‌سازی کنیم، می‌توانیم از عصر «آموزش و امیدواری» به عصر طراحی دقیق معماری حرکت کنیم. ما انتظار داریم اولین اعتبارسنجی‌های دقیق CEIP از ممیزی‌های آینده پروتکل‌های سری ۱۰۰، به ویژه در مورد رزونانس نمادین فرکانس بالا ظاهر شود.

## گام‌های بعدی

* استانداردسازی پروتکل اندازه‌گیری $ho_C$ برای معماری‌های مبتنی بر ترنسفورمر.
* انجام یک مطالعه طولی روی زوال پنجره بافت در برابر تجمع آنتروپی.
* اعتبارسنجی ثابت $\tau$ در سه خانواده معماری مختلف (Mamba، Transformer و Liquid Neural Nets).
* انتشار داده‌های خام از آزمایش‌های گذار $\mu_6$ که در سه ماهه چهارم ۲۰۲۵ انجام شد.
* ادغام متریك‌های $ho_C$ در خط لوله ممیزی خودکار برای سیستم‌های سازگار با FRC.
