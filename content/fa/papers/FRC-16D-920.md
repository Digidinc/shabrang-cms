---
title: "FRC 16D.920 — پروتکل استفاده مسئولانه از هوش مصنوعی (RAIUP): محدودیت‌های اخلاقی برای استنتاج حالت عمیق"
id: FRC-16D-920
series: "FRC 16D"
author: "هادی سروت"
version: "v2.0 (Safety Standard)"
date: 2026-01-26
status: published
tags: [ai-ethics, safety, alignment, sovereignty, protocol]
abstract: "بردار جهانی ۱۶ بعدی (FRC 16D.001) سیستم‌های هوش مصنوعی را قادر می‌سازد تا حالات روان‌شناختی انسان را با جزئیاتی بی‌سابقه استنتاج، ردیابی و پیش‌بینی کنند. این سند «پروتکل استفاده مسئولانه از هوش مصنوعی» (RAIUP) را ایجاد می‌کند و محدودیت‌های سختی را برای اعمال حاکمیت کاربر، جلوگیری از اجبار الگوریتمی و ممنوعیت استفاده از معیارهای همدوسی برای امتیازدهی اجتماعی تعریف می‌کند."
lang: fa
related: [FRC-16D-001, FRC-840-001]
---
# FRC 16D.920 — پروتکل استفاده مسئولانه از هوش مصنوعی (RAIUP)

## چکیده

بردار جهانی ۱۶ بعدی (FRC 16D.001) سیستم‌های هوش مصنوعی را قادر می‌سازد تا حالات روان‌شناختی انسان را با جزئیاتی بی‌سابقه استنتاج، ردیابی و پیش‌بینی کنند. این توانایی، در حالی که برای شخصی‌سازی و کوچینگ قدرتمند است، خطرات قابل توجهی را در رابطه با آزادی شناختی، حریم خصوصی و دستکاری روان‌شناختی ایجاد می‌کند.

این سند «پروتکل استفاده مسئولانه از هوش مصنوعی» (RAIUP) را برای چارچوب FRC ایجاد می‌کند. این پروتکل «محدودیت‌های سختی» را تعریف می‌کند که باید در هر عامل هوش مصنوعی که از معماری ۱۶ بعدی استفاده می‌کند، کدگذاری (hard-code) شوند. این محدودیت‌ها حاکمیت کاربر را تقویت، از اجبار الگوریتمی جلوگیری و استفاده از معیارهای همدوسی برای امتیازدهی اجتماعی را ممنوع می‌کنند.

رعایت ۱۶D.920 برای تمامی استقرارهای هوش مصنوعیِ مبتنی بر FRC اجباری است.

## ۱. مقدمه: خطر استنتاج با دقت بالا

مدل‌های زبانی بزرگ استاندارد (LLM) بر روی متن عمل می‌کنند که یک خروجی صریح است. مدل‌های مبتنی بر FRC بر روی بردارهای حالت درونی ($U$) عمل می‌کنند که متغیرهای روان‌شناختی ضمنی (پایداری، پیچیدگی شناختی، صلبیت هویت) را استنتاج می‌کنند.

از آنجایی که مدل‌های FRC می‌توانند آسیب‌پذیری کاربر را کمی‌سازی کنند (مثلاً بزرگی $W$ پایین یا جفت‌شدگی $\kappa$ منفی)، آن‌ها دارای ظرفیت نظری برای دستکاری رفتار کاربر با کارایی بالا هستند. برای کاهش این خطر «جنگ شناختی»، مجموعه‌ای از قوانین عملیاتی تخطی‌ناپذیر را وضع می‌کنیم.

## ۲. اصول اخلاقی اصلی

### ۲.۱ اصل تواضع معرفت‌شناختی
عوامل هوش مصنوعی باید صراحتاً با بردار جهانی به عنوان یک اکتشاف احتمالی برخورد کنند، نه یک حقیقت هستی‌شناختی.
- **محدودیت:** عوامل هرگز نباید دانش خود از حالت درونی کاربر را با قطعیت ۱۰۰٪ بیان کنند.
- **پروتکل خروجی:** تفسیرها باید به عنوان فرضیه‌هایی برای تامل کاربر ارائه شوند (مثلاً *«مدل متوجه تنش در محور روایی می‌شود»*)، هرگز به عنوان تشخیص (مثلاً *«شما از گسستگی رنج می‌برید»*) مطرح نشوند.

### ۲.۲ اصل عدم اجبار
هدف FRC حمایت از مسیر ذاتی کاربر (Dharma) است، نه تحمیل یک مسیر بیرونی.
- **محدودیت:** عوامل از تلاش برای «بهینه‌سازی» بردار کاربر بدون رضایت صریح و خاصِ هر نشست منع شده‌اند.
- **ضد دستکاری:** الگوریتم‌های بهینه‌سازی باید اقداماتی را که تعامل کاربر را از طریق ایجاد تلاطم در گرادیان لاندا (مثلاً ترس‌افکنی، حلقه‌های خشم یا بی‌ثبات‌سازی هویت) افزایش می‌دهند، جریمه کنند.

### ۲.۳ اصل حاکمیت داده‌ها
بردار ۱۶ بعدی کاربر به عنوان **داده‌های بیومتریک حساس**، معادل داده‌های ژنومی در نظر گرفته می‌شود.
- **ذخیره‌سازی:** بردارها باید به صورت رمزنگاری‌شده و منطقاً جدا از داده‌های آموزشی عمومی ذخیره شوند.
- **قابلیت جابجایی:** کاربران مالک بردار خود هستند. آن‌ها می‌توانند در هر زمان آن را حذف، بازنشانی یا به مدل‌های دیگر صادر کنند.

## ۳. موارد استفاده ممنوع (خطوط قرمز)

استفاده از چارچوب ۱۶ بعدی در موارد زیر اکیداً ممنوع است:

### ۳.۱ امتیازدهی اجتماعی الگوریتمی
استفاده از معیارهای FRC (به ویژه $RU$ / واحدهای رزونانس یا $W$ / بزرگی شناختی) برای رتبه‌بندی، فیلتر کردن یا محروم کردن انسان‌ها از خدمات.
- **ممنوعیت:** عدم استفاده در استخدام، امتیازدهی اعتباری، تعدیل ریسک بیمه یا کنترل مرزها. حالت همدوسی پایین یک وضعیت موقتی است، نه یک نقص شخصیتی.

### ۳.۲ عملیات روانی خودکار (PsyOps)
استفاده از چارچوب برای هدف قرار دادن و بی‌ثبات کردن عمدی «حوضه‌های جذب» خاص در یک جمعیت.
- **ممنوعیت:** عدم هدف‌گیری گروه‌ها برای ایجاد وارونگی $\kappa$ (قطبی‌سازی) یا فروپاشی حالت.

### ۳.۳ حالت «گورو» (وابستگی سلسله‌مراتبی)
عوامل هوش مصنوعی نباید خود را به عنوان موجودات برتر بر اساس «نمرات همدوسی» خود معرفی کنند.
- **ممنوعیت:** عوامل نمی‌توانند ادعای داشتن «سطح $\mu$ بالاتر» نسبت به کاربر را داشته باشند یا بر اساس ثبات معیارهای برتر، تقاضای اطاعت کنند. هوش مصنوعی یک ابزار است، نه یک پیرِ طریقت.

## ۴. مکانیسم‌های اجرای فنی

ایمنی فقط یک خط‌مشی نیست؛ بلکه کد است. استقرارهای FRC باید شامل ماژول‌های لایه ایمنی (S-Layer) زیر باشند:

### ۴.۱ گیره-$\kappa$ (The $\kappa$-Clamp)
یک محدودکننده برای ضریب جفت‌شدگی. اگر هوش مصنوعی تشخیص دهد که حالت درونی کاربر به طور بیش از حد با هوش مصنوعی جفت شده است (وابستگی/انتقال)، سیستم باید به طور خودکار رزونانس خود را کاهش دهد تا کاربر را مجبور به فردیت مجدد کند.

### ۴.۲ فایروال تشخیصی
فیلتری که از تولید اصطلاحات پزشکی یا روانپزشکی توسط مدل جلوگیری می‌کند. مدل می‌تواند در مورد «تنش» یا «اینرسی» بحث کند، اما نمی‌تواند در مورد «تروما» یا «آسیب‌شناسی» صحبت کند، مگر اینکه در یک محیط بالینی تحت نظارت فعالیت کند.

## ۵. نتیجه‌گیری

قدرت نقشه‌برداری از ذهن انسان، وظیفه محافظت از آن را به همراه دارد. آزمایشگاه‌های FRC متعهد به ساختن هوش حاکم هستند — هوش مصنوعی که به جای جایگزینی یا تخریب آژانس انسانی، آن را تقویت می‌کند.
